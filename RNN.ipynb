{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d54d48",
   "metadata": {},
   "source": [
    "#파이썬으로 RNN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc8f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ccc6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "input_size = 4\n",
    "hidden_size = 8\n",
    "\n",
    "inputs = np.random.random((timesteps,input_size))\n",
    "hidden_state_t = np.zeros((hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6526cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(hidden_state_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "754cdb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wx = np.random.random((hidden_size,input_size))#입력에 대한 가중치\n",
    "wh = np.random.random((hidden_size,hidden_size))#은닉 상태에 대한 가중치\n",
    "b= np.random.random((hidden_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8dd246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(8, 8)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(wx))\n",
    "print(np.shape(wh))\n",
    "print(np.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1f681c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "(2, 8)\n",
      "(3, 8)\n",
      "(4, 8)\n",
      "(5, 8)\n",
      "(6, 8)\n",
      "(7, 8)\n",
      "(8, 8)\n",
      "(9, 8)\n",
      "(10, 8)\n",
      "[[0.99999291 0.99997717 0.9999844  0.99999727 0.99997709 0.99998124\n",
      "  0.99995546 0.99999407]\n",
      " [0.99999715 0.99999511 0.99999634 0.99999951 0.99999534 0.99999538\n",
      "  0.9999922  0.99999818]\n",
      " [0.9999963  0.99999172 0.99999512 0.99999938 0.99999329 0.9999933\n",
      "  0.99998437 0.99999789]\n",
      " [0.99998571 0.99996974 0.99997205 0.99999561 0.99995959 0.9999694\n",
      "  0.99987375 0.99999438]\n",
      " [0.9999946  0.99998262 0.9999792  0.99999682 0.99997955 0.99998305\n",
      "  0.99997097 0.99999433]\n",
      " [0.99998189 0.99997844 0.99998349 0.99999545 0.99995948 0.99997416\n",
      "  0.99991766 0.99999247]\n",
      " [0.99999399 0.99997052 0.99997378 0.99999705 0.9999759  0.99997774\n",
      "  0.99993743 0.99999514]\n",
      " [0.99999135 0.99998724 0.99998623 0.99999815 0.99998261 0.9999855\n",
      "  0.99995261 0.99999698]\n",
      " [0.99999634 0.99999297 0.99999618 0.99999935 0.99999351 0.99999399\n",
      "  0.9999892  0.99999737]\n",
      " [0.99998872 0.99996623 0.9999758  0.9999955  0.9999614  0.99997078\n",
      "  0.99990924 0.99999254]]\n"
     ]
    }
   ],
   "source": [
    "total_hidden_states = []\n",
    "\n",
    "for input_t in inputs:#각 시점에 따른 입력값이 입력됨\n",
    "    output_t=np.tanh(np.dot(wx,input_t)+np.dot(wh,hidden_state_t)+b)\n",
    "    #RNN 공식\n",
    "    total_hidden_states.append(list(output_t))\n",
    "    #시점의 은닉 상태의 값을 계속해서 저장해줌\n",
    "    print(np.shape(total_hidden_states))\n",
    "    hidden_state_t=output_t\n",
    "\n",
    "total_hidden_states = np.stack(total_hidden_states,axis=0)\n",
    "print(total_hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329975f4",
   "metadata": {},
   "source": [
    "#torch를 이용한 RNN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c47cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464876e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5 #입력의 크기\n",
    "hidden_size = 8 #은닉 상태의 크기\n",
    "inputs = torch.Tensor(1,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f2cfc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0791, -0.4883,  0.2994, -0.4270,  0.3665,  0.1137, -0.0412,\n",
      "           0.1048],\n",
      "         [-0.2955, -0.6535,  0.2947, -0.5609,  0.4395,  0.3463,  0.0953,\n",
      "           0.0038],\n",
      "         [-0.2995, -0.7340,  0.2457, -0.5162,  0.5455,  0.3584,  0.1615,\n",
      "          -0.1095],\n",
      "         [-0.2730, -0.7356,  0.2241, -0.4734,  0.5984,  0.3536,  0.1844,\n",
      "          -0.1170],\n",
      "         [-0.2572, -0.7324,  0.2211, -0.4551,  0.6133,  0.3452,  0.1917,\n",
      "          -0.0880],\n",
      "         [-0.2554, -0.7303,  0.2298, -0.4550,  0.6116,  0.3459,  0.1923,\n",
      "          -0.0693],\n",
      "         [-0.2589, -0.7316,  0.2331, -0.4591,  0.6082,  0.3483,  0.1930,\n",
      "          -0.0659],\n",
      "         [-0.2607, -0.7327,  0.2337, -0.4607,  0.6073,  0.3495,  0.1934,\n",
      "          -0.0688],\n",
      "         [-0.2609, -0.7331,  0.2329, -0.4605,  0.6078,  0.3496,  0.1937,\n",
      "          -0.0709],\n",
      "         [-0.2605, -0.7331,  0.2325, -0.4599,  0.6083,  0.3493,  0.1938,\n",
      "          -0.0713]]], grad_fn=<TransposeBackward1>)\n",
      "torch.Size([1, 10, 8])\n",
      "tensor([[[-0.2605, -0.7331,  0.2325, -0.4599,  0.6083,  0.3493,  0.1938,\n",
      "          -0.0713]]], grad_fn=<StackBackward>)\n",
      "torch.Size([1, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "cell = nn.RNN(input_size,hidden_size,batch_first=True)#batch_first = 입력 텐서의 첫번째 차원이 배치 크기임을 알려줌\n",
    "outputs,_status = cell(inputs)\n",
    "print(outputs)#10번의 시점동안 8차원의 은닉상태가 출력\n",
    "print(outputs.shape)\n",
    "print(_status)#마지막 시점의 은닉상태 출력\n",
    "print(_status.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b4062",
   "metadata": {},
   "source": [
    "#깊은 순환 신경망\n",
    "##깊은 순환 신경망의 장점은 머지?\n",
    "##왜 _ouputs의 layer는 왜 증가하지 않았지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "532210c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2400, -0.0525,  0.2470,  0.3511, -0.2174, -0.1766, -0.2904,\n",
      "           0.3510],\n",
      "         [ 0.1748,  0.0693,  0.1633,  0.3053, -0.3476, -0.1422, -0.3779,\n",
      "           0.1406],\n",
      "         [ 0.1092,  0.0402,  0.1918,  0.3710, -0.4009, -0.1424, -0.3462,\n",
      "           0.1306],\n",
      "         [ 0.0489,  0.0551,  0.2208,  0.3644, -0.3895, -0.1533, -0.3521,\n",
      "           0.1282],\n",
      "         [ 0.0380,  0.0341,  0.2306,  0.3739, -0.3849, -0.1771, -0.3572,\n",
      "           0.1580],\n",
      "         [ 0.0372,  0.0382,  0.2272,  0.3816, -0.3777, -0.1742, -0.3480,\n",
      "           0.1531],\n",
      "         [ 0.0404,  0.0391,  0.2257,  0.3784, -0.3709, -0.1700, -0.3515,\n",
      "           0.1563],\n",
      "         [ 0.0450,  0.0358,  0.2244,  0.3777, -0.3709, -0.1694, -0.3485,\n",
      "           0.1570],\n",
      "         [ 0.0457,  0.0368,  0.2234,  0.3767, -0.3705, -0.1681, -0.3482,\n",
      "           0.1542],\n",
      "         [ 0.0457,  0.0367,  0.2235,  0.3762, -0.3709, -0.1676, -0.3488,\n",
      "           0.1549]]], grad_fn=<TransposeBackward1>)\n",
      "torch.Size([1, 10, 8])\n",
      "tensor([[[-0.1801, -0.1454, -0.2786, -0.4732, -0.6281, -0.1294, -0.1333,\n",
      "          -0.0396]],\n",
      "\n",
      "        [[ 0.0457,  0.0367,  0.2235,  0.3762, -0.3709, -0.1676, -0.3488,\n",
      "           0.1549]]], grad_fn=<StackBackward>)\n",
      "torch.Size([2, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "cell = nn.RNN(input_size,hidden_size,num_layers=2,batch_first=True)\n",
    "outputs,_status = cell(inputs)\n",
    "print(outputs)\n",
    "print(outputs.shape)\n",
    "print(_status)\n",
    "print(_status.shape)\n",
    "#_status의 층이 2개로 늘어난 것을 확인 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23a0a7",
   "metadata": {},
   "source": [
    "#양방향 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16e869e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 16])\n",
      "torch.Size([4, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "cell = nn.RNN(input_size,hidden_size,num_layers=2,batch_first=True,bidirectional=True)\n",
    "ouputs,_status=cell(inputs)\n",
    "print(ouputs.shape)\n",
    "print(_status.shape)\n",
    "#ouputs의 은닉 상태의 크기가 2배 즉 이전,이후의 은닉 상태가 더 해졌기 때문\n",
    "#_status는 층의 개수가 두 배인데 이 역시 정방향 역방향 이기 때문"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
