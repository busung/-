{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c47cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464876e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5 #입력의 크기\n",
    "hidden_size = 8 #은닉 상태의 크기\n",
    "inputs = torch.Tensor(1,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f2cfc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0791, -0.4883,  0.2994, -0.4270,  0.3665,  0.1137, -0.0412,\n",
      "           0.1048],\n",
      "         [-0.2955, -0.6535,  0.2947, -0.5609,  0.4395,  0.3463,  0.0953,\n",
      "           0.0038],\n",
      "         [-0.2995, -0.7340,  0.2457, -0.5162,  0.5455,  0.3584,  0.1615,\n",
      "          -0.1095],\n",
      "         [-0.2730, -0.7356,  0.2241, -0.4734,  0.5984,  0.3536,  0.1844,\n",
      "          -0.1170],\n",
      "         [-0.2572, -0.7324,  0.2211, -0.4551,  0.6133,  0.3452,  0.1917,\n",
      "          -0.0880],\n",
      "         [-0.2554, -0.7303,  0.2298, -0.4550,  0.6116,  0.3459,  0.1923,\n",
      "          -0.0693],\n",
      "         [-0.2589, -0.7316,  0.2331, -0.4591,  0.6082,  0.3483,  0.1930,\n",
      "          -0.0659],\n",
      "         [-0.2607, -0.7327,  0.2337, -0.4607,  0.6073,  0.3495,  0.1934,\n",
      "          -0.0688],\n",
      "         [-0.2609, -0.7331,  0.2329, -0.4605,  0.6078,  0.3496,  0.1937,\n",
      "          -0.0709],\n",
      "         [-0.2605, -0.7331,  0.2325, -0.4599,  0.6083,  0.3493,  0.1938,\n",
      "          -0.0713]]], grad_fn=<TransposeBackward1>)\n",
      "torch.Size([1, 10, 8])\n",
      "tensor([[[-0.2605, -0.7331,  0.2325, -0.4599,  0.6083,  0.3493,  0.1938,\n",
      "          -0.0713]]], grad_fn=<StackBackward>)\n",
      "torch.Size([1, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "cell = nn.RNN(input_size,hidden_size,batch_first=True)#batch_first = 입력 텐서의 첫번째 차원이 배치 크기임을 알려줌\n",
    "outputs,_status = cell(inputs)\n",
    "print(outputs)#10번의 시점동안 8차원의 은닉상태가 출력\n",
    "print(outputs.shape)\n",
    "print(_status)#마지막 시점의 은닉상태 출력\n",
    "print(_status.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b4062",
   "metadata": {},
   "source": [
    "#깊은 순환 신경망\n",
    "##깊은 순환 신경망의 장점은 머지?\n",
    "##왜 _ouputs의 layer는 왜 증가하지 않았지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "532210c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2400, -0.0525,  0.2470,  0.3511, -0.2174, -0.1766, -0.2904,\n",
      "           0.3510],\n",
      "         [ 0.1748,  0.0693,  0.1633,  0.3053, -0.3476, -0.1422, -0.3779,\n",
      "           0.1406],\n",
      "         [ 0.1092,  0.0402,  0.1918,  0.3710, -0.4009, -0.1424, -0.3462,\n",
      "           0.1306],\n",
      "         [ 0.0489,  0.0551,  0.2208,  0.3644, -0.3895, -0.1533, -0.3521,\n",
      "           0.1282],\n",
      "         [ 0.0380,  0.0341,  0.2306,  0.3739, -0.3849, -0.1771, -0.3572,\n",
      "           0.1580],\n",
      "         [ 0.0372,  0.0382,  0.2272,  0.3816, -0.3777, -0.1742, -0.3480,\n",
      "           0.1531],\n",
      "         [ 0.0404,  0.0391,  0.2257,  0.3784, -0.3709, -0.1700, -0.3515,\n",
      "           0.1563],\n",
      "         [ 0.0450,  0.0358,  0.2244,  0.3777, -0.3709, -0.1694, -0.3485,\n",
      "           0.1570],\n",
      "         [ 0.0457,  0.0368,  0.2234,  0.3767, -0.3705, -0.1681, -0.3482,\n",
      "           0.1542],\n",
      "         [ 0.0457,  0.0367,  0.2235,  0.3762, -0.3709, -0.1676, -0.3488,\n",
      "           0.1549]]], grad_fn=<TransposeBackward1>)\n",
      "torch.Size([1, 10, 8])\n",
      "tensor([[[-0.1801, -0.1454, -0.2786, -0.4732, -0.6281, -0.1294, -0.1333,\n",
      "          -0.0396]],\n",
      "\n",
      "        [[ 0.0457,  0.0367,  0.2235,  0.3762, -0.3709, -0.1676, -0.3488,\n",
      "           0.1549]]], grad_fn=<StackBackward>)\n",
      "torch.Size([2, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "cell = nn.RNN(input_size,hidden_size,num_layers=2,batch_first=True)\n",
    "outputs,_status = cell(inputs)\n",
    "print(outputs)\n",
    "print(outputs.shape)\n",
    "print(_status)\n",
    "print(_status.shape)\n",
    "#_status의 층이 2개로 늘어난 것을 확인 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23a0a7",
   "metadata": {},
   "source": [
    "#양방향 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16e869e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 16])\n",
      "torch.Size([4, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "cell = nn.RNN(input_size,hidden_size,num_layers=2,batch_first=True,bidirectional=True)\n",
    "ouputs,_status=cell(inputs)\n",
    "print(ouputs.shape)\n",
    "print(_status.shape)\n",
    "#ouputs의 은닉 상태의 크기가 2배 즉 이전,이후의 은닉 상태가 더 해졌기 때문\n",
    "#_status는 층의 개수가 두 배인데 이 역시 정방향 역방향 이기 때문"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
